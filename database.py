"""
æ•°æ®åº“æ¨¡å— â€”â€” è´Ÿè´£æ‰€æœ‰è·Ÿ PostgreSQL æ‰“äº¤é“çš„äº‹æƒ…
==============================================
åŒ…æ‹¬ï¼š
- åˆ›å»ºè¡¨ç»“æ„
- å­˜å‚¨å¯¹è¯è®°å½•
- å­˜å‚¨/æ£€ç´¢è®°å¿†ï¼ˆå¸¦ä¸­æ–‡åˆ†è¯å’ŒåŠ æƒæ’åºï¼‰
"""

import os
import re
from typing import Optional, List

import asyncpg

DATABASE_URL = os.getenv("DATABASE_URL", "")

# æœç´¢æƒé‡ï¼ˆå‘é‡æœç´¢åŠ å…¥åå¯é‡æ–°åˆ†é…ï¼‰
WEIGHT_KEYWORD = float(os.getenv("WEIGHT_KEYWORD", "0.5"))
WEIGHT_IMPORTANCE = float(os.getenv("WEIGHT_IMPORTANCE", "0.3"))
WEIGHT_RECENCY = float(os.getenv("WEIGHT_RECENCY", "0.2"))


# ============================================================
# è¿æ¥æ± ç®¡ç†
# ============================================================

_pool: Optional[asyncpg.Pool] = None


async def get_pool() -> asyncpg.Pool:
    global _pool
    if _pool is None:
        if not DATABASE_URL:
            raise RuntimeError("DATABASE_URL æœªè®¾ç½®ï¼")
        _pool = await asyncpg.create_pool(DATABASE_URL, min_size=1, max_size=5)
        print("âœ… æ•°æ®åº“è¿æ¥æ± å·²åˆ›å»º")
    return _pool


async def close_pool():
    global _pool
    if _pool:
        await _pool.close()
        _pool = None
        print("âœ… æ•°æ®åº“è¿æ¥æ± å·²å…³é—­")


# ============================================================
# è¡¨ç»“æ„åˆå§‹åŒ–
# ============================================================

async def init_tables():
    pool = await get_pool()
    async with pool.acquire() as conn:
        await conn.execute("""
            CREATE TABLE IF NOT EXISTS conversations (
                id              SERIAL PRIMARY KEY,
                session_id      TEXT NOT NULL,
                role            TEXT NOT NULL,
                content         TEXT NOT NULL,
                model           TEXT,
                created_at      TIMESTAMPTZ DEFAULT NOW()
            );
        """)
        
        await conn.execute("""
            CREATE TABLE IF NOT EXISTS memories (
                id              SERIAL PRIMARY KEY,
                content         TEXT NOT NULL,
                importance      INTEGER DEFAULT 5,
                source_session  TEXT,
                created_at      TIMESTAMPTZ DEFAULT NOW(),
                last_accessed   TIMESTAMPTZ DEFAULT NOW()
            );
        """)
        
        await conn.execute("""
            CREATE INDEX IF NOT EXISTS idx_memories_fts 
            ON memories 
            USING gin(to_tsvector('simple', content));
        """)
        
        await conn.execute("""
            CREATE INDEX IF NOT EXISTS idx_conversations_session 
            ON conversations (session_id, created_at);
        """)
    
    print("âœ… æ•°æ®åº“è¡¨ç»“æ„å·²å°±ç»ª")


# ============================================================
# ä¸­æ–‡åˆ†è¯å·¥å…·
# ============================================================

CJK_PATTERN = re.compile(r'[\u4e00-\u9fff\u3400-\u4dbf]')
EN_WORD_PATTERN = re.compile(r'[a-zA-Z0-9]+')
NUM_PATTERN = re.compile(r'\d{2,}')


def extract_search_keywords(query: str) -> List[str]:
    """
    ä»æŸ¥è¯¢ä¸­æå–æœç´¢å…³é”®è¯
    
    ä¸­æ–‡ï¼šæå–è¿ç»­ä¸­æ–‡ç‰‡æ®µï¼Œæ‹†æˆ2å­—å’Œ3å­—è¯ç»„ï¼ˆæ»‘åŠ¨çª—å£ï¼‰
    è‹±æ–‡ï¼šæŒ‰ç©ºæ ¼åˆ†è¯
    æ•°å­—ï¼šä¿ç•™å®Œæ•´æ•°å­—ä¸²ï¼ˆå¹´ä»½ç­‰ï¼‰
    
    ä¾‹å¦‚ï¼š
    "æ˜¥èŠ‚å¹²äº†ä»€ä¹ˆ" â†’ ["æ˜¥èŠ‚", "èŠ‚å¹²", "å¹²äº†", "äº†ä»€", "ä»€ä¹ˆ", "æ˜¥èŠ‚å¹²", "èŠ‚å¹²äº†", "å¹²äº†ä»€", "äº†ä»€ä¹ˆ"]
    "Garanæ˜¥èŠ‚"   â†’ ["Garan", "æ˜¥èŠ‚"]
    "2026é™¤å¤•"    â†’ ["2026", "é™¤å¤•"]
    """
    keywords = set()
    
    for match in EN_WORD_PATTERN.finditer(query):
        word = match.group()
        if len(word) >= 2:
            keywords.add(word)
    
    for match in NUM_PATTERN.finditer(query):
        keywords.add(match.group())
    
    chinese_chars = []
    for char in query:
        if CJK_PATTERN.match(char):
            chinese_chars.append(char)
        else:
            if len(chinese_chars) >= 2:
                _add_chinese_ngrams(chinese_chars, keywords)
            chinese_chars = []
    if len(chinese_chars) >= 2:
        _add_chinese_ngrams(chinese_chars, keywords)
    
    return list(keywords)


def _add_chinese_ngrams(chars: List[str], keywords: set):
    """æŠŠè¿ç»­ä¸­æ–‡å­—ç¬¦æ‹†æˆ2å­—å’Œ3å­—è¯ç»„"""
    text = "".join(chars)
    if len(text) <= 3:
        keywords.add(text)
    for i in range(len(text) - 1):
        keywords.add(text[i:i+2])
    if len(text) >= 3:
        for i in range(len(text) - 2):
            keywords.add(text[i:i+3])


# ============================================================
# å¯¹è¯è®°å½•æ“ä½œ
# ============================================================

async def save_message(session_id: str, role: str, content: str, model: str = ""):
    pool = await get_pool()
    async with pool.acquire() as conn:
        await conn.execute(
            "INSERT INTO conversations (session_id, role, content, model) VALUES ($1, $2, $3, $4)",
            session_id, role, content, model,
        )


async def get_recent_messages(session_id: str, limit: int = 20):
    pool = await get_pool()
    async with pool.acquire() as conn:
        rows = await conn.fetch(
            "SELECT role, content, created_at FROM conversations WHERE session_id = $1 ORDER BY created_at DESC LIMIT $2",
            session_id, limit,
        )
        return list(reversed(rows))


# ============================================================
# è®°å¿†æ“ä½œ
# ============================================================

async def save_memory(content: str, importance: int = 5, source_session: str = ""):
    pool = await get_pool()
    async with pool.acquire() as conn:
        await conn.execute(
            "INSERT INTO memories (content, importance, source_session) VALUES ($1, $2, $3)",
            content, importance, source_session,
        )


async def search_memories(query: str, limit: int = 10):
    """
    æœç´¢ç›¸å…³è®°å¿† â€”â€” ä¸­æ–‡å‹å¥½çš„åŠ æƒæœç´¢
    
    æµç¨‹ï¼š
    1. ä»æŸ¥è¯¢ä¸­æå–å…³é”®è¯ï¼ˆä¸­æ–‡bigram/trigram + è‹±æ–‡å•è¯ + æ•°å­—ï¼‰
    2. ç”¨ ILIKE é€å…³é”®è¯åŒ¹é…ï¼Œç»Ÿè®¡å‘½ä¸­æ•°
    3. åŠ æƒæ’åºï¼š
       - å…³é”®è¯å‘½ä¸­ç‡ * 0.5ï¼ˆå‘½ä¸­è¶Šå¤šè¶Šç›¸å…³ï¼‰
       - é‡è¦ç¨‹åº¦    * 0.3ï¼ˆimportance 1-10 å½’ä¸€åŒ–ï¼‰
       - å´­æ–°åº¦      * 0.2ï¼ˆè¶Šæ–°åˆ†è¶Šé«˜ï¼ŒæŒ‰å¤©è¡°å‡ï¼‰
    """
    keywords = extract_search_keywords(query)
    
    if not keywords:
        return []
    
    pool = await get_pool()
    async with pool.acquire() as conn:
        # æ¯ä¸ªå…³é”®è¯å‘½ä¸­å¾—1åˆ†
        case_parts = []
        params = []
        for i, kw in enumerate(keywords):
            case_parts.append(f"CASE WHEN content ILIKE '%' || ${i+1} || '%' THEN 1 ELSE 0 END")
            params.append(kw)
        
        hit_count_expr = " + ".join(case_parts)
        max_hits = len(keywords)
        
        # è‡³å°‘å‘½ä¸­ä¸€ä¸ªå…³é”®è¯
        where_parts = [f"content ILIKE '%' || ${i+1} || '%'" for i in range(len(keywords))]
        where_clause = " OR ".join(where_parts)
        
        limit_idx = len(keywords) + 1
        params.append(limit)
        
        # ç»¼åˆè¯„åˆ†å…¬å¼
        # recency: ä»Šå¤©â‰ˆ1.0, 1å¤©å‰â‰ˆ0.5, 7å¤©å‰â‰ˆ0.125
        sql = f"""
            SELECT 
                id, content, importance, created_at,
                ({hit_count_expr}) AS hit_count,
                (
                    {WEIGHT_KEYWORD} * ({hit_count_expr})::float / {max_hits}.0 +
                    {WEIGHT_IMPORTANCE} * importance::float / 10.0 +
                    {WEIGHT_RECENCY} * (1.0 / (1.0 + EXTRACT(EPOCH FROM (NOW() - created_at)) / 86400.0))
                ) AS score
            FROM memories
            WHERE {where_clause}
            ORDER BY score DESC, importance DESC, created_at DESC
            LIMIT ${limit_idx}
        """
        
        results = await conn.fetch(sql, *params)
        
        if results:
            print(f"ğŸ” æœç´¢ '{query}' â†’ å…³é”®è¯ {keywords[:8]}{'...' if len(keywords)>8 else ''} â†’ å‘½ä¸­ {len(results)} æ¡")
            for r in results[:3]:
                print(f"   ğŸ“Œ [score={r['score']:.3f}] (hits={r['hit_count']}, imp={r['importance']}) {r['content'][:60]}...")
            
            ids = [r["id"] for r in results]
            await conn.execute(
                "UPDATE memories SET last_accessed = NOW() WHERE id = ANY($1::int[])",
                ids,
            )
        else:
            print(f"ğŸ” æœç´¢ '{query}' â†’ å…³é”®è¯ {keywords[:8]} â†’ æ— ç»“æœ")
        
        return results


async def get_recent_memories(limit: int = 20):
    pool = await get_pool()
    async with pool.acquire() as conn:
        return await conn.fetch(
            "SELECT id, content, importance, created_at FROM memories ORDER BY created_at DESC LIMIT $1",
            limit,
        )


async def get_all_memories_count():
    pool = await get_pool()
    async with pool.acquire() as conn:
        row = await conn.fetchrow("SELECT COUNT(*) as cnt FROM memories")
        return row["cnt"]
