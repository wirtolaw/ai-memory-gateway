"""
AI Memory Gateway â€” å¸¦è®°å¿†ç³»ç»Ÿçš„ LLM è½¬å‘ç½‘å…³
=============================================
è®©ä½ çš„ AI æ‹¥æœ‰é•¿æœŸè®°å¿†ã€‚

å·¥ä½œåŸç†ï¼š
1. æ¥æ”¶å®¢æˆ·ç«¯ï¼ˆKelivo / ChatBox / ä»»ä½• OpenAI å…¼å®¹å®¢æˆ·ç«¯ï¼‰çš„æ¶ˆæ¯
2. è‡ªåŠ¨æœç´¢æ•°æ®åº“ä¸­çš„ç›¸å…³è®°å¿†ï¼Œæ³¨å…¥ system prompt
3. è½¬å‘ç»™ LLM APIï¼ˆæ”¯æŒ OpenRouter / OpenAI / ä»»ä½•å…¼å®¹æ¥å£ï¼‰
4. åå°è‡ªåŠ¨å­˜å‚¨å¯¹è¯ + ç”¨ AI æå–æ–°è®°å¿†

ç¯å¢ƒå˜é‡ MEMORY_ENABLED=false æ—¶é€€åŒ–ä¸ºçº¯è½¬å‘ç½‘å…³ï¼ˆç¬¬ä¸€é˜¶æ®µï¼‰ã€‚
"""

import os
import json
import uuid
import asyncio
import httpx
from contextlib import asynccontextmanager
from fastapi import FastAPI, Request
from fastapi.responses import StreamingResponse, JSONResponse

from database import init_tables, close_pool, save_message, search_memories, save_memory, get_all_memories_count, get_recent_memories
from memory_extractor import extract_memories

# ============================================================
# é…ç½®é¡¹ â€”â€” å…¨éƒ¨ä»ç¯å¢ƒå˜é‡è¯»å–ï¼Œéƒ¨ç½²æ—¶åœ¨äº‘å¹³å°é¢æ¿é‡Œè®¾ç½®
# ============================================================

# ä½ çš„ API Keyï¼ˆOpenRouter / OpenAI / å…¶ä»–å…¼å®¹æœåŠ¡ï¼‰
API_KEY = os.getenv("API_KEY", "")

# API åœ°å€ï¼ˆæ”¹è¿™ä¸ªå°±èƒ½åˆ‡æ¢ä¸åŒçš„ LLM æœåŠ¡å•†ï¼‰
# OpenRouter: https://openrouter.ai/api/v1/chat/completions
# OpenAI:     https://api.openai.com/v1/chat/completions
# æœ¬åœ° Ollama: http://localhost:11434/v1/chat/completions
API_BASE_URL = os.getenv("API_BASE_URL", "https://openrouter.ai/api/v1/chat/completions")

# é»˜è®¤æ¨¡å‹ï¼ˆå¦‚æœå®¢æˆ·ç«¯æ²¡æŒ‡å®šå°±ç”¨è¿™ä¸ªï¼‰
DEFAULT_MODEL = os.getenv("DEFAULT_MODEL", "anthropic/claude-sonnet-4")

# ç½‘å…³ç«¯å£
PORT = int(os.getenv("PORT", "8080"))

# è®°å¿†ç³»ç»Ÿå¼€å…³ï¼ˆæ•°æ®åº“å‡ºé—®é¢˜æ—¶å¯ä»¥ä¸´æ—¶å…³æ‰ï¼‰
MEMORY_ENABLED = os.getenv("MEMORY_ENABLED", "false").lower() == "true"

# æ¯æ¬¡æ³¨å…¥çš„æœ€å¤§è®°å¿†æ¡æ•°
MAX_MEMORIES_INJECT = int(os.getenv("MAX_MEMORIES_INJECT", "15"))

# é¢å¤–çš„è¯·æ±‚å¤´ï¼ˆæœ‰äº› API éœ€è¦ï¼Œæ¯”å¦‚ OpenRouter éœ€è¦ Refererï¼‰
EXTRA_REFERER = os.getenv("EXTRA_REFERER", "https://ai-memory-gateway.local")
EXTRA_TITLE = os.getenv("EXTRA_TITLE", "AI Memory Gateway")


# ============================================================
# äººè®¾åŠ è½½
# ============================================================

def load_system_prompt():
    """ä» system_prompt.txt æ–‡ä»¶è¯»å–äººè®¾å†…å®¹"""
    prompt_path = os.path.join(os.path.dirname(__file__), "system_prompt.txt")
    try:
        with open(prompt_path, "r", encoding="utf-8") as f:
            content = f.read().strip()
            if content:
                return content
    except FileNotFoundError:
        pass
    print("â„¹ï¸  æœªæ‰¾åˆ° system_prompt.txt æˆ–æ–‡ä»¶ä¸ºç©ºï¼Œå°†ä¸æ³¨å…¥ system prompt")
    return ""


SYSTEM_PROMPT = load_system_prompt()
if SYSTEM_PROMPT:
    print(f"âœ… äººè®¾å·²åŠ è½½ï¼Œé•¿åº¦ï¼š{len(SYSTEM_PROMPT)} å­—ç¬¦")
else:
    print("â„¹ï¸  æ— äººè®¾ï¼Œçº¯è½¬å‘æ¨¡å¼")


# ============================================================
# åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†
# ============================================================

@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ–æ•°æ®åº“ï¼Œå…³é—­æ—¶æ–­å¼€è¿æ¥"""
    if MEMORY_ENABLED:
        try:
            await init_tables()
            count = await get_all_memories_count()
            print(f"âœ… è®°å¿†ç³»ç»Ÿå·²å¯åŠ¨ï¼Œå½“å‰è®°å¿†æ•°é‡ï¼š{count}")
        except Exception as e:
            print(f"âš ï¸  æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
            print("âš ï¸  è®°å¿†ç³»ç»Ÿå°†ä¸å¯ç”¨ï¼Œä½†ç½‘å…³ä»å¯æ­£å¸¸è½¬å‘")
    else:
        print("â„¹ï¸  è®°å¿†ç³»ç»Ÿå·²å…³é—­ï¼ˆè®¾ç½® MEMORY_ENABLED=true å¼€å¯ï¼‰")
    
    yield
    
    if MEMORY_ENABLED:
        await close_pool()


app = FastAPI(title="AI Memory Gateway", version="1.0.0", lifespan=lifespan)


# ============================================================
# è®°å¿†æ³¨å…¥
# ============================================================

async def build_system_prompt_with_memories(user_message: str) -> str:
    """
    æ„å»ºå¸¦è®°å¿†çš„ system prompt
    1. ç”¨ç”¨æˆ·æ¶ˆæ¯æœç´¢ç›¸å…³è®°å¿†
    2. æ ¼å¼åŒ–æˆæ–‡æœ¬æ‹¼æ¥åˆ°äººè®¾åé¢
    """
    if not MEMORY_ENABLED:
        return SYSTEM_PROMPT
    
    try:
        memories = await search_memories(user_message, limit=MAX_MEMORIES_INJECT)
        
        if not memories:
            return SYSTEM_PROMPT
        
        memory_lines = [f"- {mem['content']}" for mem in memories]
        memory_text = "\n".join(memory_lines)
        
        enhanced_prompt = f"""{SYSTEM_PROMPT}

ã€ä»è¿‡å¾€å¯¹è¯ä¸­æ£€ç´¢åˆ°çš„ç›¸å…³è®°å¿†ã€‘
ä»¥ä¸‹æ˜¯ä¸å½“å‰è¯é¢˜å¯èƒ½ç›¸å…³çš„å†å²ä¿¡æ¯ï¼Œè‡ªç„¶åœ°èå…¥å¯¹è¯ä¸­ï¼Œä¸è¦åˆ»æ„æèµ·"æˆ‘è®°å¾—"ï¼š
{memory_text}"""
        
        print(f"ğŸ“š æ³¨å…¥äº† {len(memories)} æ¡ç›¸å…³è®°å¿†")
        return enhanced_prompt
        
    except Exception as e:
        print(f"âš ï¸  è®°å¿†æ£€ç´¢å¤±è´¥: {e}ï¼Œä½¿ç”¨çº¯äººè®¾")
        return SYSTEM_PROMPT


# ============================================================
# åå°è®°å¿†å¤„ç†
# ============================================================

async def process_memories_background(session_id: str, user_msg: str, assistant_msg: str, model: str):
    """åå°å¼‚æ­¥ï¼šå­˜å‚¨å¯¹è¯ + æå–è®°å¿†ï¼ˆä¸é˜»å¡ä¸»æµç¨‹ï¼‰"""
    try:
        await save_message(session_id, "user", user_msg, model)
        await save_message(session_id, "assistant", assistant_msg, model)
        
        # è·å–å·²æœ‰è®°å¿†ï¼Œä¼ ç»™æå–æ¨¡å‹åšå¯¹æ¯”å»é‡
        existing = await get_recent_memories(limit=80)
        existing_contents = [r["content"] for r in existing]
        
        messages_for_extraction = [
            {"role": "user", "content": user_msg},
            {"role": "assistant", "content": assistant_msg},
        ]
        new_memories = await extract_memories(messages_for_extraction, existing_memories=existing_contents)
        
        for mem in new_memories:
            await save_memory(
                content=mem["content"],
                importance=mem["importance"],
                source_session=session_id,
            )
        
        if new_memories:
            total = await get_all_memories_count()
            print(f"ğŸ’¾ å·²ä¿å­˜ {len(new_memories)} æ¡æ–°è®°å¿†ï¼Œæ€»è®¡ {total} æ¡")
            
    except Exception as e:
        print(f"âš ï¸  åå°è®°å¿†å¤„ç†å¤±è´¥: {e}")


# ============================================================
# API æ¥å£
# ============================================================

@app.get("/")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    memory_count = 0
    if MEMORY_ENABLED:
        try:
            memory_count = await get_all_memories_count()
        except:
            pass
    
    return {
        "status": "running",
        "gateway": "AI Memory Gateway v1.0",
        "system_prompt_loaded": len(SYSTEM_PROMPT) > 0,
        "system_prompt_length": len(SYSTEM_PROMPT),
        "memory_enabled": MEMORY_ENABLED,
        "memory_count": memory_count,
    }


@app.get("/v1/models")
async def list_models():
    """æ¨¡å‹åˆ—è¡¨ï¼ˆè®©å®¢æˆ·ç«¯ä¸æŠ¥é”™ï¼‰"""
    return {
        "object": "list",
        "data": [
            {
                "id": DEFAULT_MODEL,
                "object": "model",
                "created": 1700000000,
                "owned_by": "ai-memory-gateway",
            }
        ],
    }


@app.post("/v1/chat/completions")
async def chat_completions(request: Request):
    """æ ¸å¿ƒè½¬å‘æ¥å£"""
    if not API_KEY:
        return JSONResponse(
            status_code=500,
            content={"error": "API_KEY æœªè®¾ç½®ï¼Œè¯·åœ¨ç¯å¢ƒå˜é‡ä¸­é…ç½®"},
        )
    
    body = await request.json()
    messages = body.get("messages", [])
    
    # ---------- æå–ç”¨æˆ·æœ€æ–°æ¶ˆæ¯ ----------
    user_message = ""
    for msg in reversed(messages):
        if msg.get("role") == "user":
            content = msg.get("content", "")
            if isinstance(content, str):
                user_message = content
            elif isinstance(content, list):
                user_message = " ".join(
                    item.get("text", "") for item in content
                    if isinstance(item, dict) and item.get("type") == "text"
                )
            break
    
    # ---------- æ„å»º system prompt ----------
    if SYSTEM_PROMPT or (MEMORY_ENABLED and user_message):
        if MEMORY_ENABLED and user_message:
            enhanced_prompt = await build_system_prompt_with_memories(user_message)
        else:
            enhanced_prompt = SYSTEM_PROMPT
        
        if enhanced_prompt:
            has_system = any(msg.get("role") == "system" for msg in messages)
            if has_system:
                for i, msg in enumerate(messages):
                    if msg.get("role") == "system":
                        messages[i]["content"] = enhanced_prompt + "\n\n" + msg["content"]
                        break
            else:
                messages.insert(0, {"role": "system", "content": enhanced_prompt})
    
    body["messages"] = messages
    
    # ---------- æ¨¡å‹å¤„ç† ----------
    model = body.get("model", DEFAULT_MODEL)
    if not model:
        model = DEFAULT_MODEL
    body["model"] = model
    
    # ---------- ç”Ÿæˆ session ID ----------
    session_id = str(uuid.uuid4())[:8]
    
    # ---------- è½¬å‘è¯·æ±‚ ----------
    headers = {
        "Authorization": f"Bearer {API_KEY}",
        "Content-Type": "application/json",
    }
    # OpenRouter éœ€è¦çš„é¢å¤–å¤´
    if "openrouter" in API_BASE_URL:
        headers["HTTP-Referer"] = EXTRA_REFERER
        headers["X-Title"] = EXTRA_TITLE
    
    is_stream = body.get("stream", False)
    
    if is_stream:
        return StreamingResponse(
            stream_and_capture(headers, body, session_id, user_message, model),
            media_type="text/event-stream",
            headers={"Cache-Control": "no-cache", "Connection": "keep-alive"},
        )
    else:
        async with httpx.AsyncClient(timeout=300) as client:
            response = await client.post(API_BASE_URL, headers=headers, json=body)
            
            if response.status_code == 200:
                resp_data = response.json()
                assistant_msg = ""
                try:
                    assistant_msg = resp_data["choices"][0]["message"]["content"]
                except (KeyError, IndexError):
                    pass
                
                if MEMORY_ENABLED and user_message and assistant_msg:
                    asyncio.create_task(
                        process_memories_background(session_id, user_message, assistant_msg, model)
                    )
                
                return JSONResponse(status_code=200, content=resp_data)
            else:
                return JSONResponse(status_code=response.status_code, content=response.json())


async def stream_and_capture(headers: dict, body: dict, session_id: str, user_message: str, model: str):
    """æµå¼å“åº” + æ•è·å®Œæ•´å›å¤"""
    full_response = []
    
    async with httpx.AsyncClient(timeout=300) as client:
        async with client.stream("POST", API_BASE_URL, headers=headers, json=body) as response:
            async for line in response.aiter_lines():
                if line:
                    yield line + "\n"
                    if line.startswith("data: ") and line != "data: [DONE]":
                        try:
                            data = json.loads(line[6:])
                            delta = data.get("choices", [{}])[0].get("delta", {})
                            content = delta.get("content", "")
                            if content:
                                full_response.append(content)
                        except (json.JSONDecodeError, KeyError, IndexError):
                            pass
    
    assistant_msg = "".join(full_response)
    if MEMORY_ENABLED and user_message and assistant_msg:
        asyncio.create_task(
            process_memories_background(session_id, user_message, assistant_msg, model)
        )


# ============================================================
# è®°å¿†ç®¡ç†æ¥å£
# ============================================================

@app.get("/debug/memories")
async def debug_memories(q: str = "", limit: int = 20):
    """æŸ¥çœ‹å’Œæœç´¢è®°å¿†"""
    if not MEMORY_ENABLED:
        return {"error": "è®°å¿†ç³»ç»Ÿæœªå¯ç”¨ï¼ˆè®¾ç½® MEMORY_ENABLED=true å¼€å¯ï¼‰"}
    
    try:
        if q:
            memories = await search_memories(q, limit=limit)
        else:
            from database import get_recent_memories
            memories = await get_recent_memories(limit=limit)
        
        total = await get_all_memories_count()
        
        return {
            "total_memories": total,
            "query": q or "(æœ€è¿‘è®°å¿†)",
            "results": [
                {
                    "content": m["content"],
                    "importance": m["importance"],
                    "created_at": str(m["created_at"]),
                }
                for m in memories
            ],
        }
    except Exception as e:
        return {"error": str(e)}


@app.get("/import/seed-memories")
async def import_seed_memories():
    """ä¸€æ¬¡æ€§å¯¼å…¥é¢„ç½®è®°å¿†ï¼ˆä» seed_memories.pyï¼‰"""
    try:
        from seed_memories import run_seed_import
        result = await run_seed_import()
        return result
    except ImportError:
        return {"error": "æœªæ‰¾åˆ° seed_memories.pyï¼Œè¯·å‚è€ƒ seed_memories_example.py åˆ›å»º"}
    except Exception as e:
        return {"error": str(e)}


# ============================================================
# å¯åŠ¨å…¥å£
# ============================================================

if __name__ == "__main__":
    import uvicorn
    print(f"ğŸš€ AI Memory Gateway å¯åŠ¨ä¸­... ç«¯å£ {PORT}")
    print(f"ğŸ“ äººè®¾é•¿åº¦ï¼š{len(SYSTEM_PROMPT)} å­—ç¬¦")
    print(f"ğŸ¤– é»˜è®¤æ¨¡å‹ï¼š{DEFAULT_MODEL}")
    print(f"ğŸ”— API åœ°å€ï¼š{API_BASE_URL}")
    print(f"ğŸ§  è®°å¿†ç³»ç»Ÿï¼š{'å¼€å¯' if MEMORY_ENABLED else 'å…³é—­'}")
    uvicorn.run(app, host="0.0.0.0", port=PORT)
